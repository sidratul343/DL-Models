#Loading deep learning algorithm

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
import numpy as np
from glob import glob
import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

IMAGE_SIZE = [224,224]
CLASS=5
inception = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)
for layer in inception.layers:
    layer.trainable = False
x = Flatten()(inception.output)
prediction = Dense(CLASS, activation='softmax')(x)
model = Model(inputs=inception.input, outputs=prediction)


adam = keras.optimizers.Adam(lr = 0.001)
model.compile(
  loss='categorical_crossentropy',
  optimizer = adam,
  metrics=['accuracy']
)
print("\n\n")
model.summary()










train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   vertical_flip= True,
                                   horizontal_flip = True)

val_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Augmentation/aug/lung_hist_aug/geomatric/training',
                                                 target_size = (224,224),
                                                 batch_size = 64,
                                                 class_mode = 'categorical',
                                                 seed=1,
                                                 #save_to_dir="C:/rafid/keras1",
                                                 #save_prefix="kaug", 
                                                 #save_format="png"
                                                )

val_set = val_datagen.flow_from_directory('/content/drive/MyDrive/Augmentation/aug/lung_hist_aug/geomatric/validation',
                                            target_size = (224,224),
                                            batch_size = 64,
                                            class_mode = 'categorical')

model.optimizer.get_config()






from PIL import Image

filepath = "/content/drive/MyDrive/Augmentation/aug/lung_hist_aug/geomatric/adam001_val.h5"

checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_weights_only=True,
                             save_best_only=True, mode='max')

log_csv = CSVLogger('/content/drive/MyDrive/Augmentation/aug/lung_hist_aug/geomatric/adam001.csv', separator=',', append=False)   
    
callbacks_list = [checkpoint1,log_csv]

r = model.fit_generator(
    training_set,
    epochs=100,
    validation_data=val_set,
    steps_per_epoch = len(training_set),
    validation_steps=len(val_set),
    callbacks=callbacks_list,
    shuffle=False
)

model.save_weights("/content/drive/MyDrive/model weights/Nadam006V1_end.h5")
stop = time.time()
print("\n\n")
print(f"Training time: {stop - start}s")




import matplotlib.image as mpimg
import matplotlib.pyplot as plt
# plot the loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.title('Training and validation Loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')



model.load_weights('/content/drive/MyDrive/model weights/BG_sp1Adam001v1_val.h5')
preds = model.evaluate_generator(test_set)
print ("Loss = " + str(preds[0]))
print ("Test Accuracy = " + str(preds[1]))
